{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply learnings to Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: \n",
    "    path = Path('../input/titanic')\n",
    "else:\n",
    "    path = Path('titanic')\n",
    "    if not path.exists():\n",
    "        import zipfile,kaggle\n",
    "        kaggle.api.competition_download_cli(str(path))\n",
    "        zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import omdml\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moubarek, Master. Halim Gonios (\"William George\")</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2661</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Kvillner, Mr. Johan Henrik Johannesson</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 18723</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>841</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alhomaki, Mr. Ilmari Rudolf</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O2 3101287</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>721</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Harper, Miss. Annie Jessie \"Nina\"</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>248727</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Nicola-Yarred, Miss. Jamila</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2651</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "709          710         1       3   \n",
       "439          440         0       2   \n",
       "840          841         0       3   \n",
       "720          721         1       2   \n",
       "39            40         1       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "709  Moubarek, Master. Halim Gonios (\"William George\")    male   NaN      1   \n",
       "439             Kvillner, Mr. Johan Henrik Johannesson    male  31.0      0   \n",
       "840                        Alhomaki, Mr. Ilmari Rudolf    male  20.0      0   \n",
       "720                  Harper, Miss. Annie Jessie \"Nina\"  female   6.0      0   \n",
       "39                         Nicola-Yarred, Miss. Jamila  female  14.0      1   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "709      1              2661  15.2458   NaN        C  \n",
       "439      0        C.A. 18723  10.5000   NaN        S  \n",
       "840      0  SOTON/O2 3101287   7.9250   NaN        S  \n",
       "720      1            248727  33.0000   NaN        S  \n",
       "39       0              2651  11.2417   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path/'train.csv')\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "709      3    male   NaN      1      1  15.2458        C\n",
       "439      2    male  31.0      0      0  10.5000        S\n",
       "840      3    male  20.0      0      0   7.9250        S\n",
       "720      2  female   6.0      0      1  33.0000        S\n",
       "39       3  female  14.0      1      0  11.2417        C"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0      3    male  34.5      0      0   7.8292        Q\n",
       "1      3  female  47.0      1      0   7.0000        S\n",
       "2      2    male  62.0      0      0   9.6875        Q\n",
       "3      3    male  27.0      0      0   8.6625        S\n",
       "4      3  female  22.0      1      1  12.2875        S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path/'train.csv')\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_train['Pclass'].replace((1,2,3), (\"1\", \"2\", \"3\"), inplace=True)\n",
    "df_train.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "X_train = df_train.iloc[:,1:]\n",
    "y_train = df_train.iloc[:,0]\n",
    "\n",
    "X_test = pd.read_csv(path/'test.csv')\n",
    "X_test['Pclass'].replace((1,2,3), (\"1\", \"2\", \"3\"), inplace=True)\n",
    "test_passengerids = X_test['PassengerId']\n",
    "X_test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "display(X_train.head())\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age      28.0000\n",
      "SibSp     0.0000\n",
      "Parch     0.0000\n",
      "Fare     14.4542\n",
      "dtype: float64\n",
      "             0\n",
      "Pclass       3\n",
      "Sex       male\n",
      "Embarked     S\n"
     ]
    }
   ],
   "source": [
    "# impute missing values\n",
    "numeric = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "categorical = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "numeric_median = X_train[numeric].median()\n",
    "categorical_mode = X_train[categorical].mode()\n",
    "\n",
    "print(numeric_median)\n",
    "print(categorical_mode.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         177\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = X_train.isna().sum()\n",
    "temp[temp>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Age'] = X_train['Age'].fillna(X_train.groupby(['Pclass', 'Sex'])['Age'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Age'] = X_test['Age'].fillna(X_train.groupby(['Pclass', 'Sex'])['Age'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing values?\n",
      "===================\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Embarked    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train.fillna(value=numeric_median, inplace=True)\n",
    "X_train.fillna(value=categorical_mode.T.squeeze(), inplace=True)\n",
    "\n",
    "X_test.fillna(value=numeric_median, inplace=True)\n",
    "X_test.fillna(value=categorical_mode.T.squeeze(), inplace=True)\n",
    "\n",
    "print('Any missing values?')\n",
    "print('===================')\n",
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "709  25.0      1      1  15.2458         0         0         1           0   \n",
       "439  31.0      0      0  10.5000         0         1         0           0   \n",
       "840  20.0      0      0   7.9250         0         0         1           0   \n",
       "720   6.0      0      1  33.0000         0         1         0           1   \n",
       "39   14.0      1      0  11.2417         0         0         1           1   \n",
       "\n",
       "     Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "709         1           1           0           0  \n",
       "439         1           0           0           1  \n",
       "840         1           0           0           1  \n",
       "720         0           0           0           1  \n",
       "39          0           1           0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0  34.5      0      0   7.8292         0         0         1           0   \n",
       "1  47.0      1      0   7.0000         0         0         1           1   \n",
       "2  62.0      0      0   9.6875         0         1         0           0   \n",
       "3  27.0      0      0   8.6625         0         0         1           0   \n",
       "4  22.0      1      1  12.2875         0         0         1           1   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1           0           1           0  \n",
       "1         0           0           0           1  \n",
       "2         1           0           1           0  \n",
       "3         1           0           0           1  \n",
       "4         0           0           0           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert categoricals to numericals\n",
    "X_train = pd.get_dummies(X_train)\n",
    "display(X_train.head())\n",
    "X_test = pd.get_dummies(X_test)\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "709  25.0      1      1  15.2458         0         0         1           0   \n",
       "439  31.0      0      0  10.5000         0         1         0           0   \n",
       "840  20.0      0      0   7.9250         0         0         1           0   \n",
       "720   6.0      0      1  33.0000         0         1         0           1   \n",
       "39   14.0      1      0  11.2417         0         0         1           1   \n",
       "\n",
       "     Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "709         1           1           0           0  \n",
       "439         1           0           0           1  \n",
       "840         1           0           0           1  \n",
       "720         0           0           0           1  \n",
       "39          0           1           0           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0  34.5      0      0   7.8292         0         0         1           0   \n",
       "1  47.0      1      0   7.0000         0         0         1           1   \n",
       "2  62.0      0      0   9.6875         0         1         0           0   \n",
       "3  27.0      0      0   8.6625         0         0         1           0   \n",
       "4  22.0      1      1  12.2875         0         0         1           1   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         1           0           1           0  \n",
       "1         0           0           0           1  \n",
       "2         1           0           1           0  \n",
       "3         1           0           0           1  \n",
       "4         0           0           0           1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders.target_encoder import TargetEncoder\n",
    "encoder = TargetEncoder(return_df=True)\n",
    "X_train = encoder.fit_transform(X_train, y_train)\n",
    "X_test = encoder.transform(X_test)\n",
    "display(X_train.head())\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare X_train and X_test distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
      "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n",
      "Index(['Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
      "       'Sex_female', 'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "compare_intra() expects source_df and condition_series to be the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msweetviz\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msv\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# my_report = sv.analyze(df_train, target_feat = 'Survived')\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m my_report \u001b[39m=\u001b[39m sv\u001b[39m.\u001b[39;49mcompare_intra(X_train, X_test, X_train\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mtolist())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m my_report\u001b[39m.\u001b[39mshow_html()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/sweetviz/sv_public.py:34\u001b[0m, in \u001b[0;36mcompare_intra\u001b[0;34m(source_df, condition_series, names, target_feat, feat_cfg, pairwise_analysis)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompare_intra\u001b[39m(source_df: pd\u001b[39m.\u001b[39mDataFrame,\n\u001b[1;32m     28\u001b[0m                   condition_series: pd\u001b[39m.\u001b[39mSeries,\n\u001b[1;32m     29\u001b[0m                   names: Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m],\n\u001b[1;32m     30\u001b[0m                   target_feat: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m                   feat_cfg: FeatureConfig \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m                   pairwise_analysis: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(source_df) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(condition_series):\n\u001b[0;32m---> 34\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcompare_intra() expects source_df and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     35\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39mcondition_series to be the same length\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m condition_series\u001b[39m.\u001b[39mdtypes \u001b[39m!=\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcompare_intra() requires condition_series \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     38\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39mto be boolean length\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: compare_intra() expects source_df and condition_series to be the same length"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "# my_report = sv.analyze(df_train, target_feat = 'Survived')\n",
    "my_report = sv.compare_intra(X_train, X_test, X_train.columns.tolist())\n",
    "my_report.show_html() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model & finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, RepeatedStratifiedKFold, cross_val_score\n",
    "\n",
    "def y_pred(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    score = accuracy_score(y_pred_train, y_train)\n",
    "    print(score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn about `imblearn` Python library for imbalanced datasets \n",
    "[https://imbalanced-learn.org](https://imbalanced-learn.org/stable/user_guide.html#user-guide)  \n",
    "\n",
    "Most classification algorithms will only perform optimally when the number of samples of each class is roughly the same. Highly skewed datasets, where the minority is heavily outnumbered by one or more classes, have proven to be a challenge while at the same time becoming more and more common.\n",
    "One way of addressing this issue is by re-sampling the dataset as to offset this imbalance with the hope of arriving at a more robust and fair decision boundary than you would otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive random over-sampling, SMOTE, and others... \n",
    "\n",
    "One way to fight this issue is to generate new samples in the classes which are under-represented. The most naive strategy is to generate new samples by randomly sampling with replacement the current available samples. The RandomOverSampler offers such scheme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 549), (1, 549)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "# X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(data, labels, output_filename=None):\n",
    "    \"\"\"Plot confusion matrix using heatmap.\n",
    " \n",
    "    Args:\n",
    "        data (list of list): List of lists with confusion matrix data.\n",
    "        labels (list): Labels which will be plotted across x and y axis.\n",
    "        output_filename (str): Path to output file.\n",
    " \n",
    "    \"\"\"\n",
    "    sns.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(9, 6))\n",
    " \n",
    "    plt.title(\"Confusion Matrix\")\n",
    " \n",
    "    sns.set(font_scale=1.4)\n",
    "    ax = sns.heatmap(data, annot=True, cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'}, fmt='g')\n",
    " \n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    " \n",
    "    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n",
    " \n",
    "    # plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(model, X, y, labels):\n",
    "    from sklearn.metrics import ConfusionMatrixDisplay\n",
    "    # normalize confusion matrix\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    titles_options = [\n",
    "        (\"Confusion matrix, without normalization\", None),\n",
    "        (\"Normalized confusion matrix\", \"true\"),\n",
    "    ]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = ConfusionMatrixDisplay.from_estimator(\n",
    "            model,\n",
    "            X,\n",
    "            y,\n",
    "            display_labels=labels,\n",
    "            cmap=plt.cm.Blues,\n",
    "            normalize=normalize,\n",
    "        )\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        plt.grid(False)\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[medium: Precision-Recall Curves](https://medium.com/@douglaspsteen/precision-recall-curves-d32e5b290248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_recall(y_true, y_pred):\n",
    "    \n",
    "    # Convert predictions to series with index matching y_true\n",
    "    y_pred = pd.Series(y_pred, index=y_true.index)\n",
    "    \n",
    "    # Instantiate counters\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    # Determine whether each prediction is TP, FP, TN, or FN\n",
    "    for i in y_true.index: \n",
    "        if y_true[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "    \n",
    "    # Calculate true positive rate and false positive rate\n",
    "    # Use try-except statements to avoid problem of dividing by 0\n",
    "    try:\n",
    "        precision = TP / (TP + FP)\n",
    "    except:\n",
    "        precision = 1\n",
    "    \n",
    "    try:\n",
    "        recall = TP / (TP + FN)\n",
    "    except:\n",
    "        recall = 1\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.6\n"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "print(catboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Area Under Precision Recall Curve (AUPRC)](https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'function'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X40sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m thresholds:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X40sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     df_probs[\u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mround(\u001b[39m4\u001b[39m))] \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m i \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m df_probs[\u001b[39m'\u001b[39m\u001b[39mYes\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X40sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     precision, recall, threshold \u001b[39m=\u001b[39m precision_recall_curve(y_resampled, y_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X40sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     precision, recall \u001b[39m=\u001b[39m calc_precision_recall(y_resampled, df_probs[\u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mround(\u001b[39m4\u001b[39m))])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X40sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     precision_scores\u001b[39m.\u001b[39mappend(precision)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:869\u001b[0m, in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_recall_curve\u001b[39m(y_true, probas_pred, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    789\u001b[0m     \u001b[39m\"\"\"Compute precision-recall pairs for different probability thresholds.\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \n\u001b[1;32m    791\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[39m    array([0.1 , 0.35, 0.4 , 0.8 ])\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    870\u001b[0m         y_true, probas_pred, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     ps \u001b[39m=\u001b[39m tps \u001b[39m+\u001b[39m fps\n\u001b[1;32m    874\u001b[0m     precision \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdivide(tps, ps, where\u001b[39m=\u001b[39m(ps \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:742\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m    740\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 742\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m    743\u001b[0m y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    744\u001b[0m y_score \u001b[39m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/sklearn/utils/validation.py:384\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_consistent_length\u001b[39m(\u001b[39m*\u001b[39marrays):\n\u001b[1;32m    374\u001b[0m     \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[1;32m    376\u001b[0m \u001b[39m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    385\u001b[0m     uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/sklearn/utils/validation.py:384\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_consistent_length\u001b[39m(\u001b[39m*\u001b[39marrays):\n\u001b[1;32m    374\u001b[0m     \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[1;32m    376\u001b[0m \u001b[39m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    385\u001b[0m     uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/sklearn/utils/validation.py:321\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    319\u001b[0m         x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\n\u001b[1;32m    320\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(message)\n\u001b[1;32m    323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'function'>"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(verbosity=0, random_state=42)\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "probs = xgb.predict_proba(X_resampled)\n",
    "probs = xgb.predict_proba(X_resampled)\n",
    "df_probs = pd.DataFrame(probs, columns=['No', 'Yes'])\n",
    "auprc = average_precision_score(y_resampled, df_probs['Yes'])\n",
    "\n",
    "# Containers for true positive / false positive rates\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, num=10)\n",
    "\n",
    "for i in thresholds:\n",
    "    df_probs[str(i.round(4))] = [1 if k >= i else 0 for k in df_probs['Yes']]\n",
    "    precision, recall, threshold = precision_recall_curve(y_resampled, y_pred)\n",
    "    precision, recall = calc_precision_recall(y_resampled, df_probs[str(i.round(4))])\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "#AUROC\n",
    "fpr, tpr, thresholds = roc_curve(y_resampled, df_probs['Yes'], pos_label = 1) #positive class is 1; negative class is 0\n",
    "auroc = auc(fpr, tpr)\n",
    "print('auroc: {0:0.4f}'.format(auroc))\n",
    "print('AUC ROC: {0:0.4f}'.format(roc_auc_score(y_resampled, xgb.predict_proba(X_resampled)[:, 1])))\n",
    "\n",
    "# AUPRC baseline\n",
    "ratio = np.round(len(y_resampled[y_resampled==1]) / len(y_resampled), 2)\n",
    "title = 'Precision/Recall Curve (AUPRC baseline: ' + str(ratio.round(4)) + ')'\n",
    "\n",
    "plt.plot(recall_scores, precision_scores)\n",
    "plt.xlim(0.0, 1.05), plt.ylim(np.min(precision_scores)-0.05), 1.05, plt.xlabel('Recall'), plt.ylabel('Precision'), plt.title(title)\n",
    "plt.text(0.3, 0.72, 'AUPRC: ' + str(auprc.round(4)), bbox=dict(facecolor='red', alpha=0.5));\n",
    "\n",
    "df_probs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUG0lEQVR4nO3dX4xcZ3nH8d9vZnYG7wxN0nqhwU7iFBmI2xIKW4dWpU2LKE4osqi4cECNFFFZaTHiqiJFKlxwQ4UqFUSoZaEo4qJEVUnBIENaFUFQIcWb4jhx0tCtEcnKiGwITfBu4t2ZfXoxs+vxeNZz7JxzZs7x9yOtmPNnZt6XWM97znPeeR9HhAAAxVcZdwMAAOkgoANASRDQAaAkCOgAUBIEdAAoidq4vnjr1q2xY8eOcX09ABTSww8//GxEzAw7NraAvmPHDs3NzY3r6wGgkGz/eLNjpFwAoCQI6ABQEgR0ACgJAjoAlAQBHQBKYmRAt32P7WdsP7bJcdv+jO1528dtvzn9ZgIARklyhX6vpD0XOH6LpJ29v/2S/uHlNwsAcLFGzkOPiAdt77jAKXslfSG66/A+ZPtK21dHxE/SamS/H/70F/raI6dUr1W6f9WKpnr/W69V1NjYXz3nnHOPVTaO1SqW7SyaCgC5SuOHRdskPd23vdDbd15At71f3at4XXvttZf0Zf/z09P6zDfnL+m9w9g6N+D3Bfup6ugBoX/gGHz/Oa9rFTUGBp/1cxq1c7drVR5tALh4aQT0YZe3Q6tmRMQhSYckaXZ29pIqa7zrjVfr1t+8Vaud0EpnTSvtvr9OR2d6r1c7sbFvpb22sf/896ydPb7JsZX2ml54qa3VwXMGXqelYvUNCNVNBpJzB4t6dZN9mw5ElYGBqHrBz6tWuIsBJl0aAX1B0jV929slnUrhczdlW/WaVa9VpEaW35RcRGwa7EcNFhuvh+w7dyDqnHNsebl9/md31ge07qCWlmrFI+8sNh8sht/1nPv+ZCmy/sGmwiADnCONgH5Y0gHb90m6SdLzWeXPJ5ltNWpVNWrVcTdlw9pab5C50F3JeQNCZ9OBaLVv4DmzyeB0+kx784Gss6bOWnqDzFT17CAzlWiwqV7UXcvUJnc9FxrIeB6DcRoZ0G1/UdLNkrbaXpD0cUlTkhQRByUdkXSrpHlJy5LuyKqxuDiVivWKSlWvmJqcQaazFmcDfqdzNjU2JG2W7K7lwnc6L62u6YUX20Pe39nYTnGM2TwtNuz1hQaLkemzwTsaD02bTVV56H85STLL5bYRx0PSB1NrEUqtWrG21KvaUq+qd10wdu2Bu5hhdxar7TWdGZE2OzMwMG02EC2ttPXz5b47nsH3d9aUVu12W5qqdh/IDxsgLpTi6r/raZx3fnX4QDTiof9UlZllWRrb8rnApKj1ZhZN18fdkq6IULvvTiZJiuzMwOBzzgCVYCD6xUtt/Synh/4Xmlk2LEWW5K5lcEba0IFoMK3Wd0dTlof+BHRgwtjWVNWaqlbUnKCH/qNmlo2+a7lwemxw+/kXV3uvO0PPy/qh/6iZZefftVT0miu36P03XTu2OxACOoCRJnFm2bCH/qv9dzMXGCzOv2vpbDoQrfZ9x4Vmlp1pdx/6v/2GV+nqK7aM5f8TAjqAQpq0h/5fO35KB/7xB/rFS21dfcV42sBPEgEgBc169/r49Jn22NpAQAeAFDQb3YC+REAHgGJrNrqpn6UznbG1gYAOAClocYUOAOUw3cuhL60Q0AGg0Nav0HkoCgAF94qpiiqWlsmhA0Cx2VazXuMKHQDKoNmo8VAUAMqg2ahqeYWUCwAUXqtBygUASmG6TsoFAEqhyRU6AJRDixw6AJQDs1wAoCRIuQBASTTrNZ1pr6mdYg3Wi0FAB4CUbCyhO6Y8OgEdAFIy7iIXBHQASAkBHQBKokXKBQDKYb1QNFfoAFBwzTEXuSCgA0BK1gP68pjK0BHQASAl69MWT4+pahEBHQBS0mKWCwCUw5apquwJD+i299h+0va87buGHL/K9r/YPm77+7Z/I/2mAsBkW68rujSpKRfbVUl3S7pF0i5Jt9neNXDaRyUdi4g3Srpd0qfTbigAFEGzUZ3oK/TdkuYj4mRErEi6T9LegXN2Sfp3SYqI/5a0w/arU20pABRAs17T6Qme5bJN0tN92wu9ff0ekfSnkmR7t6TrJG0f/CDb+23P2Z5bXFy8tBYDwAQb55roSQK6h+yLge1PSrrK9jFJH5L0A0nn9SgiDkXEbETMzszMXGxbAWDiNRtVLY8ph15LcM6CpGv6trdLOtV/QkS8IOkOSbJtST/q/QHAZaXVqOnU/700lu9OcoV+VNJO29fbrkvaJ+lw/wm2r+wdk6Q/l/RgL8gDwGVlul7T0phy6COv0COibfuApAckVSXdExEnbN/ZO35Q0g2SvmC7I+lxSR/IsM0AMLG6OfTJTbkoIo5IOjKw72Df6+9J2plu0wCgeFoTPm0RAJDQdL2mF1c76qwNzh3JHgEdAFK0sZ7LGPLoBHQASNHGErpjyKMT0AEgRWeX0OUKHQAKbZxl6AjoAJCiJjl0ACiHs0UuyKEDQKGt59BJuQBAwa2nXHgoCgAFtzFtkRw6ABTb9NT6tEVy6ABQaJWKNV0fz3ouBHQASFmzUSPlAgBl0GrUSLkAQBk0x7SELgEdAFI2Xa8xbREAyqBFDh0AymFcZegI6ACQslajSsoFAMpgul7joSgAlEF3HnpHaznXFSWgA0DKWr0VF5dX882jE9ABIGXTY6paREAHgJSdLXJBQAeAQmuOqWoRAR0AUrZetSjvqYsEdABIWZMcOgCUw0bKJeef/xPQASBlLXLoAFAO070c+kSmXGzvsf2k7Xnbdw05foXtr9p+xPYJ23ek31QAKIaNHPqkpVxsVyXdLekWSbsk3WZ718BpH5T0eETcKOlmSX9nu55yWwGgEKoVa8tU/kUuklyh75Y0HxEnI2JF0n2S9g6cE5JeaduSWpKek5T/yjQAMCGaYyhDlySgb5P0dN/2Qm9fv89KukHSKUmPSvpwRKwNfpDt/bbnbM8tLi5eYpMBYPKNowxdkoDuIfsGlxB7p6Rjkl4j6U2SPmv7l857U8ShiJiNiNmZmZmLbCoAFEeznn/VoiQBfUHSNX3b29W9Eu93h6T7o2te0o8kvSGdJgJA8bQa+dcVTRLQj0raafv63oPOfZIOD5zzlKS3S5LtV0t6vaSTaTYUAIqkm3LJN4deG3VCRLRtH5D0gKSqpHsi4oTtO3vHD0r6hKR7bT+qbormIxHxbIbtBoCJNt2oaem55Vy/c2RAl6SIOCLpyMC+g32vT0n643SbBgDF1RpDGTp+KQoAGWg2avz0HwDKoNmoammlrYj86ooS0AEgA81GTRHSiznWFSWgA0AG1pfQzXPqIgEdADLQ2lhxkSt0ACi06TFULSKgA0AGzha5IKADQKGNowwdAR0AMrCeQ89zCV0COgBkYD2HvkzKBQCKjWmLAFASzTrTFgGgFGrVihq1Cg9FAaAMWo18V1wkoANARpoEdAAoh2ajxrRFACiDZr2aa6FoAjoAZISUCwCURKtRYx46AJTBdL3KPHQAKINmo8Y8dAAog/V56HnVFSWgA0BGmo2a1kJ6aXUtl+8joANARprrZehySrsQ0AEgI82cy9AR0AEgI3kvoUtAB4CMnK0rms/URQI6AGRkmhw6AJTD2St0AjoAFFqTgA4A5ZB3GbpEAd32HttP2p63fdeQ439l+1jv7zHbHdu/nH5zAaA4Ju4K3XZV0t2SbpG0S9Jttnf1nxMRn4qIN0XEmyT9taRvR8RzGbQXAApjqlpRvVbR6Ql6KLpb0nxEnIyIFUn3Sdp7gfNvk/TFNBoHAEWXZ13RJAF9m6Sn+7YXevvOY3ta0h5JX9rk+H7bc7bnFhcXL7atAFA40/Wqlicoh+4h+zZbOuzdkv5js3RLRByKiNmImJ2ZmUnaRgAorDyLXCQJ6AuSrunb3i7p1Cbn7hPpFgDYkOea6EkC+lFJO21fb7uubtA+PHiS7Ssk/YGkr6TbRAAormajptOTknKJiLakA5IekPSEpH+KiBO277R9Z9+p75H0rxGxlE1TAaB4mvWqlnNKudSSnBQRRyQdGdh3cGD7Xkn3ptUwACiD5oTNcgEAXKJJeygKALhE0/Wqllc6udQVJaADQIaajZraa6Ez7ezrihLQASBDeS6hS0AHgAw1c6xaREAHgAxtLKGbw4+LCOgAkKE8l9AloANAhtYDeh5TFwnoAJChZq9Q9PIKOXQAKLRmnSt0ACgFpi0CQEnwUBQASqJeq2iqai2RQweA4strxUUCOgBkrFnPZ8VFAjoAZKzVqOVSKJqADgAZm25U+ek/AJRBXkUuCOgAkLFmnYeiAFAK040qy+cCQBm0GjVy6ABQBsxDB4CSaDVqWu2EzrSzTbsQ0AEgY9O9qkVZz0UnoANAxvIqckFAB4CMbSyhm/GDUQI6AGTs7BK6pFwAoNCavRx61jNdCOgAkLG8ilwQ0AEgY61Jeihqe4/tJ23P275rk3Nutn3M9gnb3063mQBQXBvTFjOuWlQbdYLtqqS7Jb1D0oKko7YPR8TjfedcKelzkvZExFO2X5VRewGgcCZp2uJuSfMRcTIiViTdJ2nvwDnvk3R/RDwlSRHxTLrNBIDiatQqqlU8ETn0bZKe7tte6O3r9zpJV9n+lu2Hbd8+7INs77c9Z3tucXHx0loMAAVjW81GLfOUS5KA7iH7YmC7Juktkt4l6Z2S/sb26857U8ShiJiNiNmZmZmLbiwAFFWzXs085TIyh67uFfk1fdvbJZ0acs6zEbEkacn2g5JulPTDVFoJAAWXx4qLSa7Qj0raaft623VJ+yQdHjjnK5LeZrtme1rSTZKeSLepAFBczRzK0I28Qo+Itu0Dkh6QVJV0T0ScsH1n7/jBiHjC9jckHZe0JunzEfFYlg0HgCJpNqrjn7YoSRFxRNKRgX0HB7Y/JelT6TUNAMqjWa/pZ6eXM/0OfikKADlo5ZByIaADQA4mZdoiAOBlmm5kP22RgA4AOWjVa1ppr2m1s5bZdxDQASAHeSyhS0AHgBycLUOXXR6dgA4AOZhuZF+1iIAOADnIYwldAjoA5KBFDh0AymF6o1A0OXQAKDSu0AGgJDamLa4Q0AGg0M5eoZNyAYBCa9QqqpiUCwAU3npdUaYtAkAJtDIuQ0dAB4CcZL2ELgEdAHLSrGe7hC4BHQBy0iTlAgDl0GzUWG0RAMqgWa9yhQ4AZUDKBQBKosU8dAAoh2ajpjPtNbUzqitKQAeAnGwsoZvRg1ECOgDkJOsldAnoAJCT9SV0lzNaQpeADgA5afYKRZ/OaAldAjoA5KRZJ+UCAKWwnnLJauoiAR0ActKahBy67T22n7Q9b/uuIcdvtv287WO9v4+l31QAKLbpjHPotVEn2K5KulvSOyQtSDpq+3BEPD5w6nci4k8yaCMAlMIkTFvcLWk+Ik5GxIqk+yTtzaQ1AFBiW6aqmdYVTRLQt0l6um97obdv0O/YfsT2123/+rAPsr3f9pztucXFxUtoLgAUl229+8bX6LUzrUw+f2TKRZKH7IuB7f+SdF1EnLZ9q6QvS9p53psiDkk6JEmzs7ODnwEApffpfb+V2WcnuUJfkHRN3/Z2Saf6T4iIFyLidO/1EUlTtrem1koAwEhJAvpRSTttX2+7LmmfpMP9J9j+Vdvuvd7d+9yfpd1YAMDmRqZcIqJt+4CkByRVJd0TESds39k7flDSeyX9he22pBcl7YsIUioAkCOPK+7Ozs7G3NzcWL4bAIrK9sMRMTvsGL8UBYCSIKADQEkQ0AGgJAjoAFASY3soantR0o8v8e1bJT2bYnOKgD5fHujz5eHl9Pm6iJgZdmBsAf3lsD232VPesqLPlwf6fHnIqs+kXACgJAjoAFASRQ3oh8bdgDGgz5cH+nx5yKTPhcyhAwDOV9QrdADAAAI6AJTERAf0BMWpbfszvePHbb95HO1MU4I+v7/X1+O2v2v7xnG0M02j+tx33m/b7th+b57ty0KSPveKrx+zfcL2t/NuY9oS/Nu+wvZXe5XPTti+YxztTIvte2w/Y/uxTY6nH78iYiL/1F2q938l/ZqkuqRHJO0aOOdWSV9Xt6rSWyX957jbnUOff1fSVb3Xt1wOfe4775uSjkh677jbncN/5yslPS7p2t72q8bd7hz6/FFJf9t7PSPpOUn1cbf9ZfT59yW9WdJjmxxPPX5N8hV6kuLUeyV9IboeknSl7avzbmiKRvY5Ir4bET/vbT6kbgWpIktahPxDkr4k6Zk8G5eRJH1+n6T7I+IpSYqIovc7SZ9D0it7xXJa6gb0bKop5yAiHlS3D5tJPX5NckBPUpw6aQHrorjY/nxA3RG+yEb22fY2Se+RdDDHdmUpyX/n10m6yva3bD9s+/bcWpeNJH3+rKQb1C1x+aikD0fEWj7NG4vU41eSItHjkqQ4dZJziiRxf2z/oboB/fcybVH2kvT57yV9JCI6vUqHRZekzzVJb5H0dklbJH3P9kMR8cOsG5eRJH1+p6Rjkv5I0msl/Zvt70TECxm3bVxSj1+THNBHFqdOeE6RJOqP7TdK+rykWyKi6LVbk/R5VtJ9vWC+VdKtttsR8eVcWpi+pP+2n42IJUlLth+UdKOkogb0JH2+Q9Ino5tgnrf9I0lvkPT9fJqYu9Tj1ySnXEYWp+5t3957WvxWSc9HxE/ybmiKkhTkvlbS/ZL+rMBXa/1G9jkiro+IHRGxQ9I/S/rLAgdzKdm/7a9Iepvtmu1pSTdJeiLndqYpSZ+fUveORLZfLen1kk7m2sp8pR6/JvYKPZIVpz6i7pPieUnL6o7whZWwzx+T9CuSPte7Ym1HgVeqS9jnUknS54h4wvY3JB2XtCbp8xExdPpbEST87/wJSffaflTddMRHIqKwy+ra/qKkmyVttb0g6eOSpqTs4hc//QeAkpjklAsA4CIQ0AGgJAjoAFASBHQAKAkCOgCUBAEdAEqCgA4AJfH/4KGJdPw6MsMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_resampled, y_pred)\n",
    "print(thresholds)\n",
    "plt.plot(recall, precision);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744990892531876"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_predict\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X43sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# baseline\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m kfold \u001b[39m=\u001b[39m StratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBClassifier(booster\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgbtree\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, verbosity\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(xgb, X_resampled, y_resampled, cv\u001b[39m=\u001b[39mkfold)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, \\\n",
    "     roc_auc_score, accuracy_score, log_loss, plot_roc_curve, RocCurveDisplay, auc\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# baseline\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb = XGBClassifier(booster='gbtree', random_state=42, verbosity=0)\n",
    "scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "\n",
    "print('Accuracy Scores: ', scores.round(4))\n",
    "print('Mean Accuracy Score:', scores.mean().round(4))\n",
    "\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "y_pred = xgb.predict(X_resampled)\n",
    "precision, recall, thresholds = precision_recall_curve(y_resampled, y_pred)\n",
    "print('ROC AUC Score: ', roc_auc_score(y_true=y_resampled, y_score=y_pred).round(4))\n",
    "print('ROC AUC Score (Prob): {0:0.4f}'.format(roc_auc_score(y_resampled, xgb.predict_proba(X_resampled)[:, 1])))\n",
    "print('X-val predict:', cross_val_predict(xgb, X_resampled, y_resampled, cv=kfold))\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_resampled, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='example estimator')\n",
    "display.plot()  \n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_true=y_resampled, y_pred=y_pred).round(4))\n",
    "print('Log loss: ', log_loss(y_resampled, y_pred).round(4))\n",
    "\n",
    "print(classification_report(y_true=y_resampled, y_pred=y_pred))\n",
    "\n",
    "data = pd.DataFrame(confusion_matrix(y_resampled, y_pred))\n",
    "# plot_confusion_matrix(data, ['Not Survived', 'Survived'])\n",
    "# create_confusion_matrix(xgb, X_train, y_train, ['Not Survived', 'Survived'])\n",
    "\n",
    "create_confusion_matrix(xgb, X_resampled, y_resampled, ['Not Survived', 'Survived'])\n",
    "plot_roc_curve(xgb, X_resampled, y_resampled); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0:  0.97\n",
      "Precision 1:  0.98\n",
      "Recall 0:  0.98\n",
      "Recall 1:  0.97\n"
     ]
    }
   ],
   "source": [
    "# What proportion of positive identifications was actually correct?\n",
    "# Precision gives the percentage of correct predictions for each target class.\n",
    "print('Precision 0: ', np.round((538 / (538+17)),2))   # TN / (TN + FN)\n",
    "print('Precision 1: ', np.round((532 / (532+11)),2))   # TP / (TP + FP)   ***\n",
    "\n",
    "# What proportion of actual positives was identified correctly?\n",
    "# Recall gives you the percentage of positive cases that your predictions uncovered.\n",
    "print('Recall 0: ', np.round((538 / (538+11)),2))   # TN / (TN + FP)\n",
    "print('Recall 1: ', np.round((532 / (532+17)),2))   # TP / (TP + FN)   ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "ax=sns.barplot(x=[1,2,3,4,5],y=scores, color='steelblue')\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.set_xlabel('Folds')\n",
    "ax.set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Scores:  [0.8268 0.8258 0.8202 0.8483 0.7865]\n",
      "Mean Accuracy Score: 0.8215\n",
      "ROC AUC Score:  0.9617\n",
      "Accuracy:  0.9663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       549\n",
      "           1       0.97      0.94      0.96       342\n",
      "\n",
      "    accuracy                           0.97       891\n",
      "   macro avg       0.97      0.96      0.96       891\n",
      "weighted avg       0.97      0.97      0.97       891\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score\n",
    "\n",
    "# baseline\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb = XGBClassifier(booster='gbtree', random_state=42, verbosity=0)\n",
    "scores = cross_val_score(xgb, X_train, y_train, cv=kfold)\n",
    "\n",
    "print('Accuracy Scores: ', scores.round(4))\n",
    "print('Mean Accuracy Score:', scores.mean().round(4))\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_train)\n",
    "print('ROC AUC Score: ', roc_auc_score(y_true=y_train, y_score=y_pred).round(4))\n",
    "print('Accuracy: ', accuracy_score(y_true=y_train, y_pred=y_pred).round(4))\n",
    "\n",
    "print(classification_report(y_true=y_train, y_pred=y_pred))\n",
    "\n",
    "data = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "plot_confusion_matrix(data, ['Not Survived', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall: A Tug of War  \n",
    "\n",
    "To fully evaluate the effectiveness of a model, you must examine both **precision** and **recall**. Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa. Explore this notion by looking at the following figure, which shows 30 predictions made by an email classification model. Those to the right of the classification threshold are classified as \"spam\", while those to the left are classified as \"not spam.\"  \n",
    "  \n",
    "resource: [developers.google.com](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0:  0.96\n",
      "Precision 1:  0.97\n",
      "Recall 0:  0.98\n",
      "Recall 1:  0.94\n"
     ]
    }
   ],
   "source": [
    "# What proportion of positive identifications was actually correct?\n",
    "# Precision gives the percentage of correct predictions for each target class.\n",
    "# In essence, the metric tells you how often you are correct when you predict a positive.\n",
    "print('Precision 0: ', np.round((539 / (539+20)),2))   # TN / (TN + FN)\n",
    "print('Precision 1: ', np.round((322 / (322+10)),2))   # TP / (TP + FP)   ***\n",
    "\n",
    "# What proportion of actual positives was identified correctly?\n",
    "# Recall gives you the percentage of positive cases that your predictions uncovered.\n",
    "# \n",
    "print('Recall 0: ', np.round((539 / (539+10)),2))   # TN / (TN + FP)\n",
    "print('Recall 1: ', np.round((322 / (322+20)),2))   # TP / (TP + FN)   ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[539  10]\n",
      " [ 20 322]]\n",
      "Normalized confusion matrix\n",
      "[[0.98 0.02]\n",
      " [0.06 0.94]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import omdml\n",
    "xgb = XGBClassifier(booster='gbtree', random_state=42, verbosity=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "omdml.create_confusion_matrix(xgb, X_train, y_train, ['Not Survived', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8395061728395061\n",
      "0.9562289562289562\n",
      "0.8125701459034792\n",
      "0.867564534231201\n",
      "0.8148148148148148\n",
      "0.7867564534231201\n",
      "0.8428731762065096\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgb</th>\n",
       "      <th>dart</th>\n",
       "      <th>gblinear</th>\n",
       "      <th>forest</th>\n",
       "      <th>logistic</th>\n",
       "      <th>svm</th>\n",
       "      <th>knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xgb</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721527</td>\n",
       "      <td>0.772876</td>\n",
       "      <td>0.861892</td>\n",
       "      <td>0.777300</td>\n",
       "      <td>0.807600</td>\n",
       "      <td>0.307408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dart</th>\n",
       "      <td>0.721527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.647562</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.652044</td>\n",
       "      <td>0.619303</td>\n",
       "      <td>0.418765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gblinear</th>\n",
       "      <td>0.772876</td>\n",
       "      <td>0.647562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.746426</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>0.840531</td>\n",
       "      <td>0.281948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>0.861892</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.746426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750796</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.343849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>0.777300</td>\n",
       "      <td>0.652044</td>\n",
       "      <td>0.994879</td>\n",
       "      <td>0.750796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845406</td>\n",
       "      <td>0.286232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.807600</td>\n",
       "      <td>0.619303</td>\n",
       "      <td>0.840531</td>\n",
       "      <td>0.759630</td>\n",
       "      <td>0.845406</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.307408</td>\n",
       "      <td>0.418765</td>\n",
       "      <td>0.281948</td>\n",
       "      <td>0.343849</td>\n",
       "      <td>0.286232</td>\n",
       "      <td>0.213003</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               xgb      dart  gblinear    forest  logistic       svm       knn\n",
       "xgb       1.000000  0.721527  0.772876  0.861892  0.777300  0.807600  0.307408\n",
       "dart      0.721527  1.000000  0.647562  0.813242  0.652044  0.619303  0.418765\n",
       "gblinear  0.772876  0.647562  1.000000  0.746426  0.994879  0.840531  0.281948\n",
       "forest    0.861892  0.813242  0.746426  1.000000  0.750796  0.759630  0.343849\n",
       "logistic  0.777300  0.652044  0.994879  0.750796  1.000000  0.845406  0.286232\n",
       "svm       0.807600  0.619303  0.840531  0.759630  0.845406  1.000000  0.213003\n",
       "knn       0.307408  0.418765  0.281948  0.343849  0.286232  0.213003  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions with various algorithms\n",
    "y_pred_xgb = y_pred(XGBClassifier(booster='gbtree', learning_rate=0.01, n_estimators=200, max_depth=3, random_state=42))\n",
    "y_pred_dart = y_pred(XGBClassifier(booster='dart', one_drop=1, random_state=42))\n",
    "y_pred_gblinear = y_pred(XGBClassifier(booster='gblinear', random_state=42))\n",
    "y_pred_forest = y_pred(XGBRFClassifier(random_state=42))\n",
    "y_pred_logistic = y_pred(LogisticRegression(max_iter=1000, random_state=42))\n",
    "y_pred_svm = y_pred(SVC(kernel= 'linear', random_state=42, C=0.1))\n",
    "y_pred_knn = y_pred(KNeighborsClassifier(3))\n",
    "\n",
    "# combine predictions\n",
    "df_pred = pd.DataFrame(data= np.c_[y_pred_xgb, y_pred_dart, y_pred_gblinear, y_pred_forest, y_pred_logistic, y_pred_svm, y_pred_knn],\n",
    "columns=['xgb', 'dart', 'gblinear', 'forest', 'logistic', 'svm', 'knn'])\n",
    "\n",
    "df_pred.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8579036944790369\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack the least correlated model algorithms: xgb, dart, gblinear\n",
    "base_models = []\n",
    "base_models.append(('xgb',XGBClassifier(booster='gbtree', learning_rate=0.01, n_estimators=200, max_depth=3, random_state=42, verbosity=0)))\n",
    "base_models.append(('dart', XGBClassifier(booster='dart', one_drop=1, random_state=42)))\n",
    "base_models.append(('knn', KNeighborsClassifier(3)))\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "clf = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "# scores = cross_val_score(clf, X_train, y_train, cv=kfold)\n",
    "scores = cross_val_score(clf, X_resampled, y_resampled, cv=kfold)\n",
    "print(scores.mean())\n",
    "\n",
    "# fit & predict\n",
    "clf.fit(X_resampled, y_resampled,)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# create submission file\n",
    "submission_csv = pd.concat([test_passengerids, pd.Series(y_pred)], axis=1)\n",
    "submission_csv.columns = ['PassengerId', 'Survived']\n",
    "submission_csv.to_csv(path/'submission.csv', index=False)\n",
    "submission_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning hypterparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001 , Score: 0.8133416355334164\n",
      "Learning Rate: 0.01 , Score: 0.8078746367787464\n",
      "Learning Rate: 0.05 , Score: 0.8215359070153591\n",
      "Learning Rate: 0.1 , Score: 0.8333665421336655\n",
      "Learning Rate: 0.15 , Score: 0.8306102117061022\n",
      "Learning Rate: 0.2 , Score: 0.8297052718970527\n",
      "Learning Rate: 0.3 , Score: 0.8388086342880863\n",
      "Learning Rate: 0.5 , Score: 0.8488335408883355\n",
      "Learning Rate: 1.0 , Score: 0.8524865089248651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.813342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.807875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.821536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.833367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150</td>\n",
       "      <td>0.830610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.200</td>\n",
       "      <td>0.829705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.300</td>\n",
       "      <td>0.838809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.848834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.852487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate     score\n",
       "0          0.001  0.813342\n",
       "1          0.010  0.807875\n",
       "2          0.050  0.821536\n",
       "3          0.100  0.833367\n",
       "4          0.150  0.830610\n",
       "5          0.200  0.829705\n",
       "6          0.300  0.838809\n",
       "7          0.500  0.848834\n",
       "8          1.000  0.852487"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune learning rate\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "learning_rate_values = [0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 1.0]\n",
    "results = []\n",
    "\n",
    "for value in learning_rate_values:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    xgb = XGBClassifier(booster='gbtree', learning_rate=value, n_estimators=200, max_depth=3, random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "    print('Learning Rate:', value, ', Score:', scores.mean())\n",
    "    results.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(list(zip(learning_rate_values, results)), columns=['learning_rate', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "lr_results = pd.DataFrame(list(zip(learning_rate_values, results)), columns=['learning_rate', 'score'])\n",
    "plt.plot(lr_results.learning_rate, lr_results.score);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number estimators: 50 , Score: 0.831494396014944\n",
      "number estimators: 100 , Score: 0.8351598173515982\n",
      "number estimators: 150 , Score: 0.8406060606060606\n",
      "number estimators: 200 , Score: 0.850626816106268\n",
      "number estimators: 300 , Score: 0.8488003320880033\n",
      "number estimators: 400 , Score: 0.8397011207970113\n",
      "number estimators: 500 , Score: 0.8478995433789954\n",
      "number estimators: 600 , Score: 0.8506309672063097\n",
      "number estimators: 700 , Score: 0.8515442092154422\n",
      "number estimators: 800 , Score: 0.8515442092154419\n",
      "number estimators: 900 , Score: 0.8524574512245744\n",
      "number estimators: 1000 , Score: 0.8515483603154836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimator</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.831494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.835160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>0.840606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.850627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>0.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "      <td>0.839701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>0.847900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600</td>\n",
       "      <td>0.850631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>700</td>\n",
       "      <td>0.851544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>800</td>\n",
       "      <td>0.851544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>900</td>\n",
       "      <td>0.852457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.851548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimator     score\n",
       "0            50  0.831494\n",
       "1           100  0.835160\n",
       "2           150  0.840606\n",
       "3           200  0.850627\n",
       "4           300  0.848800\n",
       "5           400  0.839701\n",
       "6           500  0.847900\n",
       "7           600  0.850631\n",
       "8           700  0.851544\n",
       "9           800  0.851544\n",
       "10          900  0.852457\n",
       "11         1000  0.851548"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune n_estimators\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "n_estimator_values = [50, 100, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "results = []\n",
    "\n",
    "for value in n_estimator_values:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    xgb = XGBClassifier(booster='gbtree', learning_rate=0.3, n_estimators=value, max_depth=3, random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "    print('number estimators:', value, ', Score:', scores.mean())\n",
    "    results.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(list(zip(n_estimator_values, results)), columns=['n_estimator', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth: 1 , Score: 0.8014653383146534\n",
      "Max depth: 2 , Score: 0.8296720630967205\n",
      "Max depth: 3 , Score: 0.8397135740971358\n",
      "Max depth: 4 , Score: 0.8460813615608137\n",
      "Max depth: 5 , Score: 0.8433333333333334\n",
      "Max depth: 6 , Score: 0.8488044831880448\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.801465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.829672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.839714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.846081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.843333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.848804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth     score\n",
       "0          1  0.801465\n",
       "1          2  0.829672\n",
       "2          3  0.839714\n",
       "3          4  0.846081\n",
       "4          5  0.843333\n",
       "5          6  0.848804"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune max_depth\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "max_depth_values = [1,2,3,4,5,6]\n",
    "results = []\n",
    "\n",
    "for value in max_depth_values:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    xgb = XGBClassifier(booster='gbtree', learning_rate=0.2, n_estimators=200, max_depth=value, random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "    print('Max depth:', value, ', Score:', scores.mean())\n",
    "    results.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(list(zip(max_depth_values, results)), columns=['max_depth', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma: 0 , Score: 0.8397135740971358\n",
      "gamma: 1 , Score: 0.825134910751349\n",
      "gamma: 2 , Score: 0.8132793690327936\n",
      "gamma: 3 , Score: 0.8178497301784973\n",
      "gamma: 4 , Score: 0.8178414279784143\n",
      "gamma: 5 , Score: 0.8151266085512662\n",
      "gamma: 6 , Score: 0.8151224574512245\n",
      "gamma: 7 , Score: 0.8160273972602738\n",
      "gamma: 8 , Score: 0.8096637608966375\n",
      "gamma: 9 , Score: 0.8132959734329596\n",
      "gamma: 10 , Score: 0.8087505188875053\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.839714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.825135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.813279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.817850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.817841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.815127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.815122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.816027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.809664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.813296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.808751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gamma     score\n",
       "0       0  0.839714\n",
       "1       1  0.825135\n",
       "2       2  0.813279\n",
       "3       3  0.817850\n",
       "4       4  0.817841\n",
       "5       5  0.815127\n",
       "6       6  0.815122\n",
       "7       7  0.816027\n",
       "8       8  0.809664\n",
       "9       9  0.813296\n",
       "10     10  0.808751"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune gamma\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "gamma_values = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "results = []\n",
    "\n",
    "for value in gamma_values:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    xgb = XGBClassifier(booster='gbtree', learning_rate=0.2, \n",
    "                                          n_estimators=200, \n",
    "                                          max_depth=3,\n",
    "                                          gamma=value, \n",
    "                                          random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "    print('gamma:', value, ', Score:', scores.mean())\n",
    "    results.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(list(zip(gamma_values, results)), columns=['gamma', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_child_weight: 0 , Score: 0.8451764217517642\n",
      "min_child_weight: 1 , Score: 0.8397135740971358\n",
      "min_child_weight: 2 , Score: 0.8360481527604815\n",
      "min_child_weight: 3 , Score: 0.8378787878787879\n",
      "min_child_weight: 4 , Score: 0.8369696969696969\n",
      "min_child_weight: 5 , Score: 0.8369863013698631\n",
      "min_child_weight: 6 , Score: 0.8333374844333749\n",
      "min_child_weight: 7 , Score: 0.8378829389788294\n",
      "min_child_weight: 8 , Score: 0.8369738480697386\n",
      "min_child_weight: 9 , Score: 0.8287588210875884\n",
      "min_child_weight: 10 , Score: 0.8269406392694064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.845176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.839714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.836048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.837879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.836970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.836986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.833337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.837883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.836974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.828759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.826941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_child_weight     score\n",
       "0                  0  0.845176\n",
       "1                  1  0.839714\n",
       "2                  2  0.836048\n",
       "3                  3  0.837879\n",
       "4                  4  0.836970\n",
       "5                  5  0.836986\n",
       "6                  6  0.833337\n",
       "7                  7  0.837883\n",
       "8                  8  0.836974\n",
       "9                  9  0.828759\n",
       "10                10  0.826941"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune min_child_weight\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "min_child_weight_values = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "results = []\n",
    "\n",
    "for value in min_child_weight_values:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    xgb = XGBClassifier(booster='gbtree', learning_rate=0.2, \n",
    "                                          n_estimators=200, \n",
    "                                          max_depth=3,\n",
    "                                          min_child_weight=value, \n",
    "                                          random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "    print('min_child_weight:', value, ', Score:', scores.mean())\n",
    "    results.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(list(zip(min_child_weight_values, results)), columns=['min_child_weight', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0 , Score: 0.5\n",
      "subsample: 0.1 , Score: 0.816928185969282\n",
      "subsample: 0.2 , Score: 0.8442424242424243\n",
      "subsample: 0.3 , Score: 0.836052303860523\n",
      "subsample: 0.4 , Score: 0.8396720630967206\n",
      "subsample: 0.5 , Score: 0.8433291822332919\n",
      "subsample: 0.7 , Score: 0.8497052718970528\n",
      "subsample: 0.8 , Score: 0.8551515151515151\n",
      "subsample: 0.9 , Score: 0.8588044831880449\n",
      "subsample: 1 , Score: 0.8451764217517642\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.816928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.844242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.836052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.839672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.843329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.849705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.855152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.845176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample     score\n",
       "0        0.0  0.500000\n",
       "1        0.1  0.816928\n",
       "2        0.2  0.844242\n",
       "3        0.3  0.836052\n",
       "4        0.4  0.839672\n",
       "5        0.5  0.843329\n",
       "6        0.7  0.849705\n",
       "7        0.8  0.855152\n",
       "8        0.9  0.858804\n",
       "9        1.0  0.845176"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune subsample\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "subsample_values = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9, 1]\n",
    "results = []\n",
    "\n",
    "for value in subsample_values:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    xgb = XGBClassifier(booster='gbtree', learning_rate=0.2, \n",
    "                                          n_estimators=200, \n",
    "                                          max_depth=3,\n",
    "                                          min_child_weight=0,\n",
    "                                          subsample=value, \n",
    "                                          random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "    print('subsample:', value, ', Score:', scores.mean())\n",
    "    results.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(list(zip(subsample_values, results)), columns=['subsample', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsample: 0 , Score: 0.8588044831880449\n",
      "subsample: 0.1 , Score: 0.8588044831880449\n",
      "subsample: 0.2 , Score: 0.8588044831880449\n",
      "subsample: 0.3 , Score: 0.8588044831880449\n",
      "subsample: 0.4 , Score: 0.8588044831880449\n",
      "subsample: 0.5 , Score: 0.8588044831880449\n",
      "subsample: 0.7 , Score: 0.8588044831880449\n",
      "subsample: 0.8 , Score: 0.8588044831880449\n",
      "subsample: 0.9 , Score: 0.8588044831880449\n",
      "subsample: 1 , Score: 0.8588044831880449\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subsample</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subsample     score\n",
       "0        0.0  0.858804\n",
       "1        0.1  0.858804\n",
       "2        0.2  0.858804\n",
       "3        0.3  0.858804\n",
       "4        0.4  0.858804\n",
       "5        0.5  0.858804\n",
       "6        0.7  0.858804\n",
       "7        0.8  0.858804\n",
       "8        0.9  0.858804\n",
       "9        1.0  0.858804"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finetune subsample\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "subsample_values = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9, 1]\n",
    "results = []\n",
    "\n",
    "for value in subsample_values:\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    xgb = XGBClassifier(booster='gbtree', learning_rate=0.2, \n",
    "                                          n_estimators=200, \n",
    "                                          max_depth=3,\n",
    "                                          min_child_weight=0,\n",
    "                                          subsample=0.9, \n",
    "                                          random_state=42, n_jobs=-1)\n",
    "    scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "    print('subsample:', value, ', Score:', scores.mean())\n",
    "    results.append(scores.mean())\n",
    "\n",
    "pd.DataFrame(list(zip(subsample_values, results)), columns=['subsample', 'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch  \n",
    "Continue with a gridsearch but  \n",
    "* n_estimators = 200  \n",
    "* learning_rate = 0.2  \n",
    "* max_depth = 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, RepeatedStratifiedKFold\n",
    "\n",
    "def grid_search(params, random=False): \n",
    "    \n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=42, use_label_encoder=False)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    # kfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=2)\n",
    "    \n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, scoring='accuracy', cv=kfold, n_iter=20, n_jobs=-1, random_state=42)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "    \n",
    "    grid.fit(X_resampled, y_resampled)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Best score: {:.5f}\".format(best_score))\n",
    "\n",
    "    print(xgb)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search(params={'learning_rate':[0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 1.0],\n",
    "                    'n_estimators':[50, 100, 150, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                    'max_depth':[1,2,3,4,5,6],\n",
    "                    # 'min_child_weight':[3], \n",
    "                    # 'subsample':[.2, .4, .6, .8], \n",
    "                    # 'colsample_bytree':[0.9],\n",
    "                    # 'colsample_bylevel':[0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    # 'colsample_bynode':[0.6, 0.7, 0.8, 0.9, 1]\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  [0.8409 0.8545 0.8409 0.8447 0.8813]\n",
      "Mean Accuracy:  0.8525\n",
      "\n",
      "Accuracy:  0.9735883424408015\n",
      "ROC AUC:  0.9735883424408015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       549\n",
      "           1       0.98      0.97      0.97       549\n",
      "\n",
      "    accuracy                           0.97      1098\n",
      "   macro avg       0.97      0.97      0.97      1098\n",
      "weighted avg       0.97      0.97      0.97      1098\n",
      "\n",
      "ROC AUC:  [0.8948 0.909  0.9067 0.93   0.9291]\n",
      "Mean ROC AUC:  0.9139\n"
     ]
    }
   ],
   "source": [
    "# Best params: {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 500}\n",
    "# Best score: 0.86159\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=None,\n",
    "                colsample_bynode=None, colsample_bytree=None,\n",
    "                enable_categorical=False, gamma=None, gpu_id=None,\n",
    "                importance_type=None, interaction_constraints=None,\n",
    "                learning_rate=None, max_delta_step=None, max_depth=None,\n",
    "                min_child_weight=None, monotone_constraints=None,\n",
    "                n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
    "                predictor=None, random_state=42, reg_alpha=None, reg_lambda=None,\n",
    "                scale_pos_weight=None, subsample=None, tree_method=None,\n",
    "                use_label_encoder=False, validate_parameters=None,\n",
    "                verbosity=None)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold, scoring='accuracy')\n",
    "print('Accuracy: ', scores.round(4), )\n",
    "print('Mean Accuracy: ', scores.mean().round(4))\n",
    "print('')\n",
    "\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "y_pred_train = xgb.predict(X_resampled)\n",
    "print('Accuracy: ', accuracy_score(y_resampled, y_pred_train))\n",
    "print('ROC AUC: ', roc_auc_score(y_resampled, y_pred_train))\n",
    "print(classification_report(y_resampled, y_pred_train))\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold, scoring='roc_auc')\n",
    "print('ROC AUC: ', scores.round(4), )\n",
    "print('Mean ROC AUC: ', scores.mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Scores:  [0.81363636 0.79090909 0.82727273 0.78995434 0.84018265]\n",
      "Train STD:  0.019800346878233472\n",
      "Train Score:  0.8123910336239103\n",
      "X_train accuracy: 0.824226\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 7, got 12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000063?line=24'>25</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mpredict(X_resampled)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000063?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mX_train accuracy: \u001b[39m\u001b[39m{0:0.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(accuracy_score(y_resampled, y_pred)))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000063?line=27'>28</a>\u001b[0m y_pred \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000063?line=28'>29</a>\u001b[0m submission_csv \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([test_passengerids, pd\u001b[39m.\u001b[39mSeries(y_pred)], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000063?line=29'>30</a>\u001b[0m submission_csv\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mPassengerId\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/sklearn.py:1284\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m   1276\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1277\u001b[0m     X: array_like,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     iteration_range: Optional[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1283\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 1284\u001b[0m     class_probs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   1285\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1286\u001b[0m         output_margin\u001b[39m=\u001b[39;49moutput_margin,\n\u001b[1;32m   1287\u001b[0m         ntree_limit\u001b[39m=\u001b[39;49mntree_limit,\n\u001b[1;32m   1288\u001b[0m         validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1289\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1290\u001b[0m         iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m   1291\u001b[0m     )\n\u001b[1;32m   1292\u001b[0m     \u001b[39mif\u001b[39;00m output_margin:\n\u001b[1;32m   1293\u001b[0m         \u001b[39m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m         \u001b[39mreturn\u001b[39;00m class_probs\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/sklearn.py:881\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m    880\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[1;32m    882\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    883\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[1;32m    884\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    885\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m    886\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    887\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m    888\u001b[0m         )\n\u001b[1;32m    889\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[1;32m    890\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m     \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/core.py:2018\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   2015\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2016\u001b[0m         )\n\u001b[1;32m   2017\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features() \u001b[39m!=\u001b[39m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m-> 2018\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2019\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFeature shape mismatch, expected: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_features()\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2020\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2021\u001b[0m         )\n\u001b[1;32m   2023\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _is_pandas_df, _transform_pandas_df\n\u001b[1;32m   2024\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _array_interface\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 7, got 12"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "# xgb = XGBClassifier(booster='gbtree', objective='binary:logistic',, random_state=42)  \n",
    "# xgb = XGBClassifier(booster='gbtree', learning_rate=0.02, n_estimators=200, max_depth=3, random_state=42)\n",
    "# xgb = XGBRFClassifier(random_state=42)\n",
    "# xgb = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# xgb = SVC(kernel= 'linear', random_state=42, C=0.1)  \n",
    "# xgb = XGBClassifier(subsample=0.7, n_estimators=1000, max_depth= 3, learning_rate=0.3, gamma=4, colsample_bytree=0.7)p\n",
    "# xgb = XGBClassifier(booster='gbtree', params=best_params, random_state=42)\n",
    "# xgb = XGBClassifier(booster='gbtree', learning_rate=0.2, \n",
    "#                                           n_estimators=500, \n",
    "#                                           max_depth=6,\n",
    "#                                           random_state=42, n_jobs=-1)\n",
    "xgb = XGBClassifier(booster='gbtree', learning_rate=0.01, n_estimators=200, max_depth=3, random_state=42, verbosity=0)\n",
    "\n",
    "# xgb.fit(X_train, y_train)\n",
    "# xgb.fit(X_resampled, y_resampled)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "scores = cross_val_score(xgb, X_resampled, y_resampled, cv=kfold)\n",
    "xgb.fit(X_resampled, y_resampled)\n",
    "print('Train Scores: ', scores)\n",
    "print('Train STD: ', scores.std())\n",
    "print('Train Score: ', scores.mean())\n",
    "\n",
    "y_pred = xgb.predict(X_resampled)\n",
    "print('X_train accuracy: {0:0.6f}'.format(accuracy_score(y_resampled, y_pred)))\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "submission_csv = pd.concat([test_passengerids, pd.Series(y_pred)], axis=1)\n",
    "submission_csv.columns = ['PassengerId', 'Survived']\n",
    "submission_csv.to_csv(path/'submission.csv', index=False)\n",
    "submission_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=-1,\n",
      "              num_parallel_tree=1,\n",
      "              params={'colsample_bylevel': 0.9, 'colsample_bynode': 0.6,\n",
      "                      'colsample_bytree': 0.9, 'learning_rate': 0.2,\n",
      "                      'max_depth': 3, 'min_child_weight': 3,\n",
      "                      'n_estimators': 200, 'subsample': 0.4},\n",
      "              predictor='auto', random_state=42, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done! Use 'show' commands to display/save.   || [100%]   00:00 -> (00:00 left)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "my_report = sv.analyze(df_train, target_feat = 'Survived')\n",
    "my_report.show_html() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced dataset?\n",
      "   survived\n",
      "0       549\n",
      "1       342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Imbalanced dataset?')\n",
    "print(pd.DataFrame(Counter(df['Survived']), index=['survived']).transpose().sort_index())\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical:  ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "numerical:  ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = df.columns[df.dtypes==object].tolist()\n",
    "numerical_columns = df.columns[df.dtypes!=object].tolist()\n",
    "\n",
    "print('categorical: ', categorical_columns)\n",
    "print('numerical: ', numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `Pclass` from numeric to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical:  ['Pclass', 'Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "numerical:  ['PassengerId', 'Survived', 'Age', 'SibSp', 'Parch', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "df['Pclass'].replace((1,2,3), (\"1\", \"2\", \"3\"), inplace=True)\n",
    "categorical_columns = df.columns[df.dtypes==object].tolist()\n",
    "numerical_columns = df.columns[df.dtypes!=object].tolist()\n",
    "\n",
    "print('categorical: ', categorical_columns)\n",
    "print('numerical: ', numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_title(name):\n",
    "    pattern = ',\\s.*\\.\\s'\n",
    "    match_results = re.search(pattern, name)\n",
    "    result = match_results.group()[2:-2]\n",
    "    if result not in ['Mr', 'Miss', 'Mrs', 'Master', 'Dr', 'Rev']:\n",
    "        result = 'Other'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "X = df.iloc[:, 2:]\n",
    "y = df.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class CustomPreprossessing(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # my custom code\n",
    "        X['title'] = X.apply(lambda x: get_title(x['Name']), axis=1)\n",
    "        X['Cabin'].fillna('Empty', inplace=True)\n",
    "        # X['cab'] = [i if i in ['A', 'B', 'C', 'D', 'E', 'F'] else 'Other' for i in X['Cabin'].str[:1]]\n",
    "        X = X.loc[:, ~X.columns.isin(['Name', 'Ticket', 'Cabin'])]\n",
    "        return X      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Moubarek, Master. Halim Gonios (\"William George\")</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2661</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Kvillner, Mr. Johan Henrik Johannesson</td>\n",
       "      <td>male</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A. 18723</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>841</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alhomaki, Mr. Ilmari Rudolf</td>\n",
       "      <td>male</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O2 3101287</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>721</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Harper, Miss. Annie Jessie \"Nina\"</td>\n",
       "      <td>female</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>248727</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Nicola-Yarred, Miss. Jamila</td>\n",
       "      <td>female</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2651</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Penasco y Castellana, Mr. Victor de Satode</td>\n",
       "      <td>male</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C65</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Thorneycroft, Mr. Percival</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>376564</td>\n",
       "      <td>16.1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>825</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Panula, Master. Urho Abraham</td>\n",
       "      <td>male</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3101295</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>804</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thomas, Master. Assad Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2625</td>\n",
       "      <td>8.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "709          710         1       3   \n",
       "439          440         0       2   \n",
       "840          841         0       3   \n",
       "720          721         1       2   \n",
       "39            40         1       3   \n",
       "..           ...       ...     ...   \n",
       "505          506         0       1   \n",
       "639          640         0       3   \n",
       "878          879         0       3   \n",
       "824          825         0       3   \n",
       "803          804         1       3   \n",
       "\n",
       "                                                  Name     Sex    Age  SibSp  \\\n",
       "709  Moubarek, Master. Halim Gonios (\"William George\")    male    NaN      1   \n",
       "439             Kvillner, Mr. Johan Henrik Johannesson    male  31.00      0   \n",
       "840                        Alhomaki, Mr. Ilmari Rudolf    male  20.00      0   \n",
       "720                  Harper, Miss. Annie Jessie \"Nina\"  female   6.00      0   \n",
       "39                         Nicola-Yarred, Miss. Jamila  female  14.00      1   \n",
       "..                                                 ...     ...    ...    ...   \n",
       "505         Penasco y Castellana, Mr. Victor de Satode    male  18.00      1   \n",
       "639                         Thorneycroft, Mr. Percival    male    NaN      1   \n",
       "878                                 Laleff, Mr. Kristo    male    NaN      0   \n",
       "824                       Panula, Master. Urho Abraham    male   2.00      4   \n",
       "803                    Thomas, Master. Assad Alexander    male   0.42      0   \n",
       "\n",
       "     Parch            Ticket      Fare Cabin Embarked  \n",
       "709      1              2661   15.2458   NaN        C  \n",
       "439      0        C.A. 18723   10.5000   NaN        S  \n",
       "840      0  SOTON/O2 3101287    7.9250   NaN        S  \n",
       "720      1            248727   33.0000   NaN        S  \n",
       "39       0              2651   11.2417   NaN        C  \n",
       "..     ...               ...       ...   ...      ...  \n",
       "505      0          PC 17758  108.9000   C65        C  \n",
       "639      0            376564   16.1000   NaN        S  \n",
       "878      0            349217    7.8958   NaN        S  \n",
       "824      1           3101295   39.6875   NaN        S  \n",
       "803      1              2625    8.5167   NaN        C  \n",
       "\n",
       "[712 rows x 12 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SIZE\n",
    "df[0:TRAIN_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>547</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beane, Mrs. Edward (Ethel Clarke)</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2908</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Partner, Mr. Austen</td>\n",
       "      <td>male</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113043</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>C124</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pain, Dr. Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244278</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Berglund, Mr. Karl Ivar Sven</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PP 4348</td>\n",
       "      <td>9.3500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                               Name     Sex  \\\n",
       "886          547         1       2  Beane, Mrs. Edward (Ethel Clarke)  female   \n",
       "887          332         0       1                Partner, Mr. Austen    male   \n",
       "888          399         0       2                   Pain, Dr. Alfred    male   \n",
       "889          871         0       3                  Balkic, Mr. Cerin    male   \n",
       "890          226         0       3       Berglund, Mr. Karl Ivar Sven    male   \n",
       "\n",
       "      Age  SibSp  Parch   Ticket     Fare Cabin Embarked  kfold  \n",
       "886  19.0      1      0     2908  26.0000   NaN        S     -1  \n",
       "887  45.5      0      0   113043  28.5000  C124        S     -1  \n",
       "888  23.0      0      0   244278  10.5000   NaN        S     -1  \n",
       "889  26.0      0      0   349248   7.8958   NaN        S     -1  \n",
       "890  22.0      0      0  PP 4348   9.3500   NaN        S     -1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df[\"kfold\"] = -1\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000080?line=17'>18</a>\u001b[0m kf \u001b[39m=\u001b[39m model_selection\u001b[39m.\u001b[39mStratifiedKFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)     \u001b[39m#, random_state=42)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000080?line=19'>20</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000080?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(kf\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39mdf, y\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39;49mtarget\u001b[39m.\u001b[39mvalues)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000080?line=21'>22</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_idx), \u001b[39mlen\u001b[39m(val_idx))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdreger/Documents/mygit/Hands-On-Gradient-Boosting-with-XGBoost-and-Scikit-learn/Chapter10/Titanic.ipynb#ch0000080?line=22'>23</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[val_idx, \u001b[39m'\u001b[39m\u001b[39mkfold\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fold\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'target'"
     ]
    }
   ],
   "source": [
    "# custom encoder for dummies\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "# from . import dispatcher\n",
    "\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "df[\"kfold\"] = -1\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=False)     #, random_state=42)\n",
    "\n",
    "df.head()\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X=df, y=df.target.values)):\n",
    "    print(len(train_idx), len(val_idx))\n",
    "    df.loc[val_idx, 'kfold'] = fold\n",
    "\n",
    "# df.to_csv(path/'train_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin \n",
    "\n",
    "class NullValueImputer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        for column in X.columns.tolist():\n",
    "            if column in X.columns[X.dtypes==object].tolist():\n",
    "                X[column] = X[column].fillna(X[column].mode()[0])     # omd: should I change to: .mode()[0] ?\n",
    "            else:\n",
    "                X[column]=X[column].fillna(-999.0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TargetEncode(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, categories='auto', k=1, f=1, \n",
    "                 noise_level=0, random_state=None):\n",
    "        if type(categories)==str and categories!='auto':\n",
    "            self.categories = [categories]\n",
    "        else:\n",
    "            self.categories = categories\n",
    "        self.k = k\n",
    "        self.f = f\n",
    "        self.noise_level = noise_level\n",
    "        self.encodings = dict()\n",
    "        self.prior = None\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def add_noise(self, series, noise_level):\n",
    "        return series * (1 + noise_level *   \n",
    "                         np.random.randn(len(series)))\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if type(self.categories)=='auto':\n",
    "            self.categories = np.where(X.dtypes == type(object()))[0]\n",
    "        \n",
    "        temp = X.loc[:, self.categories].copy()\n",
    "        temp['target'] = y\n",
    "        self.prior = np.mean(y)\n",
    "        for variable in self.categories:\n",
    "            avg = (temp.groupby(by=variable)['target']\n",
    "                       .agg(['mean', 'count']))\n",
    "            # Compute smoothing \n",
    "            smoothing = (1 / (1 + np.exp(-(avg['count'] - self.k) /                 \n",
    "                         self.f)))\n",
    "            # The bigger the count the less full_avg is accounted\n",
    "            self.encodings[variable] = dict(self.prior * (1 -  \n",
    "                             smoothing) + avg['mean'] * smoothing)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        Xt = X.copy()\n",
    "        for variable in self.categories:\n",
    "            Xt[variable].replace(self.encodings[variable], \n",
    "                                 inplace=True)\n",
    "            unknown_value = {value:self.prior for value in \n",
    "                             X[variable].unique() \n",
    "                             if value not in \n",
    "                             self.encodings[variable].keys()}\n",
    "            if len(unknown_value) > 0:\n",
    "                Xt[variable].replace(unknown_value, inplace=True)\n",
    "            Xt[variable] = Xt[variable].astype(float)\n",
    "            if self.noise_level > 0:\n",
    "                if self.random_state is not None:\n",
    "                    np.random.seed(self.random_state)\n",
    "                Xt[variable] = self.add_noise(Xt[variable], \n",
    "                                              self.noise_level)\n",
    "        return Xt\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "class SparseMatrix(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        None\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        categorical_columns= X.columns[X.dtypes==object].tolist()\n",
    "        ohe = OneHotEncoder(handle_unknown='ignore')               # omd: may need to change later\n",
    "        # ohe = OneHotEncoder() \n",
    "        hot = ohe.fit_transform(X[categorical_columns])\n",
    "        cold_df = X.select_dtypes(exclude=[\"object\"])\n",
    "        cold = csr_matrix(cold_df)\n",
    "        final_sparse_matrix = hstack((hot, cold))\n",
    "        final_csr_matrix = final_sparse_matrix.tocsr()\n",
    "        return final_csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=2)\n",
    "\n",
    "data_pipeline = Pipeline([('custom_prepross', CustomPreprossessing()), ('null_imputer', NullValueImputer()), ('sparse', SparseMatrix())])\n",
    "X_train_transformed = data_pipeline.fit_transform(X_train)\n",
    "X_test_transformed = data_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model):\n",
    "    # roc_scores = cross_val_score(model, X_train_transformed, y_train, scoring='roc_auc', cv=kfold)\n",
    "    # roc = (roc_scores.mean())\n",
    "    accuracy_scores = cross_val_score(model, X_train_transformed, y_train, scoring='accuracy', cv=kfold)\n",
    "    acc = (accuracy_scores.mean())\n",
    "    print(model)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:53:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:53:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:53:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:53:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:53:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=-999.0, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8008753226349455"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val(XGBClassifier(missing=-999.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:20:44] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95c819e670&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95c819ef70&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95c819e6d0&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;gblinear&#x27;,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, enable_categor...\n",
       "                               gamma=None, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.5,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               min_child_weight=None, missing=-999.0,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=None, predictor=None,\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=0,\n",
       "                               scale_pos_weight=1, subsample=None,\n",
       "                               tree_method=None, validate_parameters=1,\n",
       "                               verbosity=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95c819e670&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95c819ef70&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95c819e6d0&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;gblinear&#x27;,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, enable_categor...\n",
       "                               gamma=None, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.5,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               min_child_weight=None, missing=-999.0,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=None, predictor=None,\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=0,\n",
       "                               scale_pos_weight=1, subsample=None,\n",
       "                               tree_method=None, validate_parameters=1,\n",
       "                               verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomPreprossessing</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.CustomPreprossessing object at 0x7f95c819e670&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NullValueImputer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.NullValueImputer object at 0x7f95c819ef70&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SparseMatrix</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.SparseMatrix object at 0x7f95c819e6d0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gblinear&#x27;, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.5, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=-999.0, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=None,\n",
       "              predictor=None, random_state=0, reg_alpha=0, reg_lambda=0,\n",
       "              scale_pos_weight=1, subsample=None, tree_method=None,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('custom_prepross',\n",
       "                 <__main__.CustomPreprossessing object at 0x7f95c819e670>),\n",
       "                ('null_imputer',\n",
       "                 <__main__.NullValueImputer object at 0x7f95c819ef70>),\n",
       "                ('sparse', <__main__.SparseMatrix object at 0x7f95c819e6d0>),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gblinear',\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, enable_categor...\n",
       "                               gamma=None, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.5,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               min_child_weight=None, missing=-999.0,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=None, predictor=None,\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=0,\n",
       "                               scale_pos_weight=1, subsample=None,\n",
       "                               tree_method=None, validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# booster='gblinear'\n",
    "full_pipeline = Pipeline([('custom_prepross', CustomPreprossessing()),\n",
    "                          ('null_imputer', NullValueImputer()), \n",
    "                          ('sparse', SparseMatrix()), \n",
    "                          ('xgb', XGBClassifier(booster='gblinear', missing=-999.0))])\n",
    "full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95c9b9ed60&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95ea36d460&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95ea36d400&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBRFClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                 colsample_bylevel=1, colsample_bytree=1,\n",
       "                                 enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=&#x27;&#x27;, max_delta_step=0,\n",
       "                                 max_depth=6, min_child_weight=1,\n",
       "                                 missing=-999.0, monotone_constraints=&#x27;()&#x27;,\n",
       "                                 n_estimators=80, n_jobs=8,\n",
       "                                 num_parallel_tree=80,\n",
       "                                 objective=&#x27;binary:logistic&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                                 random_state=0, reg_alpha=0,\n",
       "                                 scale_pos_weight=1, tree_method=&#x27;exact&#x27;,\n",
       "                                 validate_parameters=1, verbosity=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95c9b9ed60&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95ea36d460&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95ea36d400&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBRFClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                                 colsample_bylevel=1, colsample_bytree=1,\n",
       "                                 enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints=&#x27;&#x27;, max_delta_step=0,\n",
       "                                 max_depth=6, min_child_weight=1,\n",
       "                                 missing=-999.0, monotone_constraints=&#x27;()&#x27;,\n",
       "                                 n_estimators=80, n_jobs=8,\n",
       "                                 num_parallel_tree=80,\n",
       "                                 objective=&#x27;binary:logistic&#x27;, predictor=&#x27;auto&#x27;,\n",
       "                                 random_state=0, reg_alpha=0,\n",
       "                                 scale_pos_weight=1, tree_method=&#x27;exact&#x27;,\n",
       "                                 validate_parameters=1, verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomPreprossessing</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.CustomPreprossessing object at 0x7f95c9b9ed60&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NullValueImputer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.NullValueImputer object at 0x7f95ea36d460&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SparseMatrix</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.SparseMatrix object at 0x7f95ea36d400&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRFClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBRFClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "                colsample_bytree=1, enable_categorical=False, gamma=0,\n",
       "                gpu_id=-1, importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "                max_delta_step=0, max_depth=6, min_child_weight=1,\n",
       "                missing=-999.0, monotone_constraints=&#x27;()&#x27;, n_estimators=80,\n",
       "                n_jobs=8, num_parallel_tree=80, objective=&#x27;binary:logistic&#x27;,\n",
       "                predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "                scale_pos_weight=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "                verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('custom_prepross',\n",
       "                 <__main__.CustomPreprossessing object at 0x7f95c9b9ed60>),\n",
       "                ('null_imputer',\n",
       "                 <__main__.NullValueImputer object at 0x7f95ea36d460>),\n",
       "                ('sparse', <__main__.SparseMatrix object at 0x7f95ea36d400>),\n",
       "                ('xgb',\n",
       "                 XGBRFClassifier(base_score=0.5, booster='gbtree',\n",
       "                                 colsample_bylevel=1, colsample_bytree=1,\n",
       "                                 enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "                                 importance_type=None,\n",
       "                                 interaction_constraints='', max_delta_step=0,\n",
       "                                 max_depth=6, min_child_weight=1,\n",
       "                                 missing=-999.0, monotone_constraints='()',\n",
       "                                 n_estimators=80, n_jobs=8,\n",
       "                                 num_parallel_tree=80,\n",
       "                                 objective='binary:logistic', predictor='auto',\n",
       "                                 random_state=0, reg_alpha=0,\n",
       "                                 scale_pos_weight=1, tree_method='exact',\n",
       "                                 validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "full_pipeline = Pipeline([('custom_prepross', CustomPreprossessing()),\n",
    "                          ('null_imputer', NullValueImputer()), \n",
    "                          ('sparse', SparseMatrix()), \n",
    "                          ('xgb', XGBRFClassifier(n_estimators=80, missing=-999.0))])\n",
    "full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:47:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95fbe31bb0&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95fbe311c0&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95fbe318e0&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;dart&#x27;,\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               ga...\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=-999.0,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, one_drop=True,\n",
       "                               predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "                               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                               tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "                               verbosity=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95fbe31bb0&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95fbe311c0&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95fbe318e0&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;dart&#x27;,\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               ga...\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=-999.0,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, one_drop=True,\n",
       "                               predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "                               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                               tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "                               verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomPreprossessing</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.CustomPreprossessing object at 0x7f95fbe31bb0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NullValueImputer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.NullValueImputer object at 0x7f95fbe311c0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SparseMatrix</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.SparseMatrix object at 0x7f95fbe318e0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;dart&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=-999.0,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, one_drop=True, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "              verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('custom_prepross',\n",
       "                 <__main__.CustomPreprossessing object at 0x7f95fbe31bb0>),\n",
       "                ('null_imputer',\n",
       "                 <__main__.NullValueImputer object at 0x7f95fbe311c0>),\n",
       "                ('sparse', <__main__.SparseMatrix object at 0x7f95fbe318e0>),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='dart',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               ga...\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=-999.0,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, one_drop=True,\n",
       "                               predictor='auto', random_state=0, reg_alpha=0,\n",
       "                               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# booster='dart'\n",
    "full_pipeline = Pipeline([('custom_prepross', CustomPreprossessing()),\n",
    "                          ('null_imputer', NullValueImputer()), \n",
    "                          ('sparse', SparseMatrix()), \n",
    "                          ('xgb', XGBClassifier(booster='dart', one_drop=True, missing=-999.0))])\n",
    "full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:00:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:576: \n",
      "Parameters: { \"params\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:00:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95c9b8f430&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95c9b8ff40&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95c9b8f1f0&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,...\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               params={&#x27;colsample_bytree&#x27;: 0.5, &#x27;gamma&#x27;: 0.5,\n",
       "                                       &#x27;learning_rate&#x27;: 0.01, &#x27;max_depth&#x27;: 6,\n",
       "                                       &#x27;min_child_weight&#x27;: 1,\n",
       "                                       &#x27;n_estimators&#x27;: 100,\n",
       "                                       &#x27;scale_pos_weight&#x27;: 1, &#x27;subsample&#x27;: 1},\n",
       "                               predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "                               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                               tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "                               verbosity=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;custom_prepross&#x27;,\n",
       "                 &lt;__main__.CustomPreprossessing object at 0x7f95c9b8f430&gt;),\n",
       "                (&#x27;null_imputer&#x27;,\n",
       "                 &lt;__main__.NullValueImputer object at 0x7f95c9b8ff40&gt;),\n",
       "                (&#x27;sparse&#x27;, &lt;__main__.SparseMatrix object at 0x7f95c9b8f1f0&gt;),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;,\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,...\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               params={&#x27;colsample_bytree&#x27;: 0.5, &#x27;gamma&#x27;: 0.5,\n",
       "                                       &#x27;learning_rate&#x27;: 0.01, &#x27;max_depth&#x27;: 6,\n",
       "                                       &#x27;min_child_weight&#x27;: 1,\n",
       "                                       &#x27;n_estimators&#x27;: 100,\n",
       "                                       &#x27;scale_pos_weight&#x27;: 1, &#x27;subsample&#x27;: 1},\n",
       "                               predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "                               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                               tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "                               verbosity=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomPreprossessing</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.CustomPreprossessing object at 0x7f95c9b8f430&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NullValueImputer</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.NullValueImputer object at 0x7f95c9b8ff40&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SparseMatrix</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.SparseMatrix object at 0x7f95c9b8f1f0&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=-999.0,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1,\n",
       "              params={&#x27;colsample_bytree&#x27;: 0.5, &#x27;gamma&#x27;: 0.5,\n",
       "                      &#x27;learning_rate&#x27;: 0.01, &#x27;max_depth&#x27;: 6,\n",
       "                      &#x27;min_child_weight&#x27;: 1, &#x27;n_estimators&#x27;: 100,\n",
       "                      &#x27;scale_pos_weight&#x27;: 1, &#x27;subsample&#x27;: 1},\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method=&#x27;exact&#x27;,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('custom_prepross',\n",
       "                 <__main__.CustomPreprossessing object at 0x7f95c9b8f430>),\n",
       "                ('null_imputer',\n",
       "                 <__main__.NullValueImputer object at 0x7f95c9b8ff40>),\n",
       "                ('sparse', <__main__.SparseMatrix object at 0x7f95c9b8f1f0>),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,...\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1,\n",
       "                               params={'colsample_bytree': 0.5, 'gamma': 0.5,\n",
       "                                       'learning_rate': 0.01, 'max_depth': 6,\n",
       "                                       'min_child_weight': 1,\n",
       "                                       'n_estimators': 100,\n",
       "                                       'scale_pos_weight': 1, 'subsample': 1},\n",
       "                               predictor='auto', random_state=0, reg_alpha=0,\n",
       "                               reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params = {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300}     # from GridSearch below\n",
    "# params = {'subsample': 1, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.7, 'colsample_bynode': 0.8}\n",
    "params = {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'scale_pos_weight': 1, 'subsample': 1}\n",
    "full_pipeline = Pipeline([('custom_prepross', CustomPreprossessing()),\n",
    "                          ('null_imputer', NullValueImputer()), \n",
    "                          ('sparse', SparseMatrix()), \n",
    "                          ('xgb', XGBClassifier(params=params, missing=-999.0))])\n",
    "full_pipeline.fit(X_train, y_train)\n",
    "# print(XGBClassifier(params=params, missing=-999.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.884731\n",
      "Test accuracy: 0.834081\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "y_pred = full_pipeline.predict(X_train)\n",
    "print('Train accuracy: {0:0.6f}'.format(accuracy_score(y_train, y_pred)))\n",
    "y_pred = full_pipeline.predict(X_test)\n",
    "print('Test accuracy: {0:0.6f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score 'Hold-Out' Test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Kaggle score | hyperparameters | Accuracy Score |  Date  |\n",
    "|----------|---------------- |--------|---------|\n",
    "| 0.72966  |  'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300 | train: 0.83388  test: 0.8116591928251121 | Jul 17, 2022 |\n",
    "| 0.72966  |  'subsample': 1, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.7, 'colsample_bynode': 0.8 | train: 0.83238 test: 0.8116591928251121 | Jul 17, 2022 |\n",
    "| 0.73684  |  booster='dart', one_drop=True | train: 0.979042  test: 0.802691 | Jul 17, 2022 |\n",
    "| 0.77272  |  XGBRFClassifier | train: 0.886228  test: 0.829596 | Jul 17, 2022 |\n",
    "|  0.75358 | XGBClassifier(booster='gblinear') | train: 0.835329  test: 0.807175  | Jul 17, 2022 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n"
     ]
    }
   ],
   "source": [
    "df_holdout = pd.read_csv(path/'test.csv')\n",
    "X_holdout = df_holdout.iloc[:, 1:]\n",
    "y_holdout = full_pipeline.predict(X_holdout)\n",
    "df_submission = df_holdout[['PassengerId']]\n",
    "df_submission['Survived'] = y_holdout.tolist()\n",
    "print(df_submission.head())\n",
    "df_submission.to_csv(path/'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold, RepeatedStratifiedKFold\n",
    "\n",
    "def grid_search(params, random=False): \n",
    "    \n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', random_state=42, use_label_encoder=False)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
    "    # kfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=2)\n",
    "    \n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, scoring='accuracy', cv=kfold, n_iter=20, n_jobs=-1, random_state=2)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, scoring='accuracy', cv=kfold, n_jobs=-1)\n",
    "    \n",
    "    grid.fit(X_train_transformed, y_train)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Best score: {:.5f}\".format(best_score))\n",
    "\n",
    "    print(xgb)\n",
    "\n",
    "    xgb = XGBClassifier(booster='gbtree', objective='binary:logistic', \n",
    "                        random_state=2, use_label_encoder=False, \n",
    "                        params=best_params, missing=-999.0)\n",
    "    print(xgb)\n",
    "    xgb.fit(X_train_transformed, y_train)\n",
    "    y_pred = xgb.predict(X_test_transformed)\n",
    "    print('Test score: {0:0.8f}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:09:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliverdreger/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/oliverdreger/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/oliverdreger/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/oliverdreger/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/oliverdreger/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/oliverdreger/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/oliverdreger/opt/anaconda3/envs/dcr/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:09:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:09:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:32] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:32] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:37] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:37] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:37] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:10:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:05] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:05] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:16] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:33] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:51] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:52] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:53] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:11:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:02] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:11] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:16] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:16] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:32] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:32] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:32] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:34] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:36] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:38] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:39] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:40] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:43] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:44] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:44] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:47] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:48] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:49] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:50] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:54] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:55] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:57] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:58] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:12:59] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:00] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:01] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:03] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:04] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:05] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:05] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:05] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:06] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:08] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:09] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:10] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:12] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:13] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:14] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:18] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:19] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:23] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:24] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:25] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:26] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:27] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:28] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:29] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:30] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:31] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:13:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params: {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'scale_pos_weight': 1, 'subsample': 1}\n",
      "Best score: 0.83076\n",
      "XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=-999.0, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=2, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "XGBClassifier(base_score=None, booster='gbtree', colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=-999.0, monotone_constraints=None,\n",
      "              n_estimators=100, n_jo...rallel_tree=None,\n",
      "              params={'colsample_bytree': 0.5, 'gamma': 0.5,\n",
      "                      'learning_rate': 0.01, 'max_depth': 6,\n",
      "                      'min_child_weight': 1, 'n_estimators': 100,\n",
      "                      'scale_pos_weight': 1, 'subsample': 1},\n",
      "              predictor=None, random_state=2, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "[11:13:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:576: \n",
      "Parameters: { \"params\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:13:35] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117948562/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test score: 0.84304933\n"
     ]
    }
   ],
   "source": [
    "# Best params: {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'scale_pos_weight': 1, 'subsample': 1}\n",
    "# Best score: 0.83076\n",
    "# Test score: 0.84304933\n",
    "\n",
    "Best params: {'colsample_bytree': 0.5, 'gamma': 0.5, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'scale_pos_weight': 1, 'subsample': 1}\n",
    "Best score: 0.83076\n",
    "\n",
    "grid_search(params={'learning_rate':[0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "                    'n_estimators':[100, 200, 300],\n",
    "                    'scale_pos_weight':[1],\n",
    "                    'max_depth':[6],\n",
    "                    'gamma':[0.5], # Best score: 0.83532     #Test score: 0.81165919\n",
    "                    'min_child_weight':[1],  # Best score: 0.83532   # Test score: 0.81165919\n",
    "                    'subsample':[1],\n",
    "                    'colsample_bytree':[0.5, 0.7, 0.8, 0.9, 1]\n",
    "                    },\n",
    "            random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if test dataset has additional categories for a variable?  \n",
    "[Regular Expressions in Python](http://chris35wills.github.io/courses/Intermediate_python/regexp/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path/'train.csv')\n",
    "df_test = pd.read_csv(path/'test.csv')\n",
    "X_train = df_train.drop(['Survived'], axis=1)\n",
    "X_test = df_test.copy()\n",
    "df = pd.concat([X_train, X_test], axis=0)\n",
    "combine = [X_train, X_test]\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Pclass            0\n",
       "Name              0\n",
       "Sex               0\n",
       "Age             263\n",
       "SibSp             0\n",
       "Parch             0\n",
       "Ticket            0\n",
       "Fare              1\n",
       "Cabin          1014\n",
       "Embarked          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_title(name):\n",
    "    pattern = ',\\s.*\\.\\s'\n",
    "    match_results = re.search(pattern, name)\n",
    "    result = match_results.group()[2:-2]\n",
    "    if result not in ['Mr', 'Miss', 'Mrs', 'Master', 'Dr', 'Rev']:\n",
    "        result = 'Other'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df.apply(lambda x: get_title(x['Name']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked title  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S    Mr  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   Mrs  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  Miss  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   Mrs  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S    Mr  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        757\n",
       "Miss      260\n",
       "Mrs       196\n",
       "Master     61\n",
       "Other      19\n",
       "Rev         8\n",
       "Dr          8\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: [kaggle.com](https://www.kaggle.com/code/omd123/titanic-data-science-solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match found\n"
     ]
    }
   ],
   "source": [
    "txt = 'Braund, Mr. Owen Harris'\n",
    "re.search('Owen', txt)\n",
    "\n",
    "if re.search('Owen', txt):\n",
    "    print('match found')\n",
    "else:\n",
    "    print('no match found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method=&#x27;exact&#x27;, use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can values be combined?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0.792000</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>0.697802</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0.156673</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  count\n",
       "Title                    \n",
       "Sir       1.000000      1\n",
       "Countess  1.000000      1\n",
       "Ms        1.000000      1\n",
       "Mme       1.000000      1\n",
       "Lady      1.000000      1\n",
       "Mlle      1.000000      2\n",
       "Mrs       0.792000    125\n",
       "Miss      0.697802    182\n",
       "Master    0.575000     40\n",
       "Col       0.500000      2\n",
       "Major     0.500000      2\n",
       "Dr        0.428571      7\n",
       "Mr        0.156673    517\n",
       "Jonkheer  0.000000      1\n",
       "Don       0.000000      1\n",
       "Rev       0.000000      6\n",
       "Capt      0.000000      1"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "# pd.crosstab(df['Title'], df['Sex'])\n",
    "print('Can values be combined?')\n",
    "pd.concat([X_train, df_train['Survived']], axis=1).groupby(['Title'])['Survived'].agg(\n",
    "    ['mean', 'count']).sort_values(by=['mean'], ascending=False)\n",
    "\n",
    "# Sir, Countess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female  male\n",
       "Title                 \n",
       "Capt           0     1\n",
       "Col            0     2\n",
       "Countess       1     0\n",
       "Don            0     1\n",
       "Dr             1     6\n",
       "Jonkheer       0     1\n",
       "Lady           1     0\n",
       "Major          0     2\n",
       "Master         0    40\n",
       "Miss         182     0\n",
       "Mlle           2     0\n",
       "Mme            1     0\n",
       "Mr             0   517\n",
       "Mrs          125     0\n",
       "Ms             1     0\n",
       "Rev            0     6\n",
       "Sir            0     1"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "pd.crosstab(X_train['Title'], X_train['Sex'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('dcr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1d8f5fbaca742faf657a0ec32bfad031ab0ec50a0f634b2e6034c00f0a73e54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
